---
title: "Projet de Modélisation Prédictive"
author: "Arthur Reidenbach et Raphael Bordas"
date: "Mars 2024"
output: bookdown::pdf_document2
toc-title: "Sommaire"
urlcolor: blue
---

```{r setup, include = FALSE}
# rm(list = objects())
# graphics.off()
library(tidyverse)
library(lubridate)
library(quantreg)
library(mgcv)
library(readxl)
library(qgam)
library(mgcv)
library(ggpubr)
library(forecast)

# custom utilities scripts
source('utils/score.R')
source('utils/utils.R')
source('_01_preprocess_data.R') # to get the data for the plots

knitr::opts_template$set(centered = list(
  # fig.width = 10, fig.height = 6,
  # fig.retina = 2, 
  out.width = '60%',
  fig.align = 'center',
  echo = FALSE
))

knitr::opts_template$set(fullwidth = list(
  fig.width = 12, fig.height = 6,
  # fig.retina = 2, 
  out.width = '100%',
  fig.align = 'center',
  echo = FALSE
))
```


Code lié à ce projet disponible sur ce [dépôt GitHub](https://github.com/raphbrd/modelisation_predictive).


# Motivation

Avec la part croissante des énergies renouvelables dans le mix électrique en France, il devient majeur de pouvoir prédire la demande nette de production électrique, c'est-à-dire la charge globale du réseau (`Load` dans le jeu de données) moins les productions renouvelables (`Solar_power` et `Wind_power`). L'augmentation de la demande brute avec les voitures électriques est également un enjeu majeur des futures prédictions de consommation, dont les caractéristiques majeurs vont ainsi être amenées à changer. Une rupture, dont l'importance est encore inconnue, est à prévoir à la fois sur les modalités de production et les habitudes de consommation. C'est dans ce cadre que le jeu de données fourni se propose de prédire la demande nette lors de la période de sobriété énergétique de septembre 2022 à octobre 2023, en apprenant sur les données de la dernière décénnie (2013 - 2022).

# Nettoyage des données et analyse exploratoire

## Choix des données d'entrainement

Les données test ne comportant pas la demande nette, nous procédons par validation sur un sous-échantillon du jeu d'entraînement original (`Data0` dans le code). Plusieurs méthodes peuvent être envisagées :

1. Entraînement entre 2013 et 2021 inclus, validation entre le 01/01/2022 et le 01/09/2022. 

2. Entraînement entre 2018 et 2021 inclus, validation entre le 01/01/2022 et le 01/09/2022. 

3. Entraînement entre le 01/01/2018 et le 01/09/2022, validation sur 365 points aléatoirement choisis entre le 01/01/2021 et le 01/09/2022 et exclus de l'entraînement

La motivation pour entrainer les modèles à partir de 2018 (méthodes 2 et 3) vient essentiellement des observations suivantes : le changement de comportement de certaines séries temporelles (par exemple augmentation de la production éolienne observable sur la Figure \@ref(fig:data-evol), panel de gauche), de la définition et du calcul de la nébulosité pondéré par la production (`Nebulosity_weighted`) à partir de 2018 (Figure \@ref(fig:data-evol), panel de droite). De manière générale, il a été observé de meilleures performances à modèles identiques lorsque l'entraînement commence en 2018. 

De plus, il est également intéressant de prendre des points de validation aléatoire, pour éviter une évaluation biaisée de la performance : la méthode 2 n'évalue la performance d'un modèle que sur 3 saisons. Or, ainsi que le montre la Figure \@ref(fig:train-val-data), la série temporelle d'intérêt présente une saisonnalité annuelle très marquée. Il est donc primodial d'évaluer également le modèle sur octobre-novembre-décembre.

## Données externes

La série temporelle d'intérêt a la particularité de couvrir toute la période de la pandémie du Covid-19 en 2020-2021. En effet, d'un point de vue descriptif, il est observé une baisse drastique et anormale de la consommation (Figure \@ref(fig:covid-impact)). Deux solutions ont alors été testé pour prendre en compte ces déviations par rapport à la tendance avant et après le Covid :

- un codage 'one-hot' des trois confinements: du 17/03/2020 au 11/05/2020, du 30/10/2020 au 12/15/2020 et du 04/03/2021 au 03/05/2021. $1$ dénote alors la présence d'un confinement, $0$ son absence.

- un indice de confinement (*strengency index*^[Hale, T., Angrist, N., Goldszmidt, R. et al. A global panel database of pandemic policies (Oxford COVID-19 Government Response Tracker). Nat Hum Behav 5, 529–538 (2021). https://doi.org/10.1038/s41562-021-01079-8]) pour prendre en compte l'effet de la pandémie du Covid-19 sur la consommation électrique en France. Dans ce cadre, nous avons testé l'incorporation de cet indice comme covariable mais aussi l'exclusion de l'entrainement des périodes avec un indice supérieur à 80 (correspondant au premier confinement du printemps 2020).

```{r train-val-data, fig.cap = "Two versions of the training and validation datasets", opts.label="fullwidth"}
par(mfrow=c(1, 2))
plot(train_data$Date, train_data$Net_demand, type='l', xlim=range(train_data$Date, val_data$Date), main = "", xlab = "Date", ylab = "Net demand (MW)")
lines(val_data$Date, val_data$Load, type='l', col = "blue")
legend("top", legend = c("Train", "Validation"), col = c("black", "blue"), ncol = 2, lty = 1)

plot(train_data2$Date, train_data2$Net_demand, type='l', xlim=range(train_data$Date, val_data$Date), main = "", xlab = "Date", ylab = "Net demand (MW)")
points(val_data2$Date, val_data2$Load, pch = 3, col = "blue")
legend("top", legend = c("Train", "Validation"), col = c("black", "blue"), ncol = 2, lty = 1)
```

```{r data-evol, fig.cap = "Evolution of some time series before and after 2018 (red line on Jan. 1st 2018)", opts.label="fullwidth"}
col <- yarrr::piratepal("basel")
par(mfrow=c(1,2))
plot(Data0$Date, Data0$Load, type='l', col=col[1], ylim = c(0, 90000), xlab = "Date", ylab = "Load (MW)")
lines(Data0$Date, Data0$Solar_power, col=col[2])
lines(Data0$Date, Data0$Wind_power, col=col[3])
abline(v = Data0$Date[Data0$Date == "2018-01-01"], col = "red", lty = 2)

plot(Data0$Date, Data0$Nebulosity_weighted, pch=3,  col="darkgrey", xlab = "Date", ylab = "Weighted Nebulosity")
abline(v = Data0$Date[Data0$Date == "2018-01-01"], col = "red", lty = 2)
```

```{r covid-impact, opts.label="centered", fig.cap="Impact of Covid over the net demand. Comparing time series between March 17th and May 11th of each year."}
Data0 %>% filter(Year %in% c(2018, 2019, 2020, 2021),
                 Month %in% c(3, 4, 5),
                 toy < 0.360,
                 toy > 0.208) %>%
  ggplot(aes(confinement1, Net_demand, colour = as.factor(Year))) +
  geom_boxplot() + facet_grid() +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(x = "Lockdown", y = "Net demand (MW)", colour = "Year") +
  scale_x_discrete(labels = c("Outside lockdown", "During lockdown"))
```

## Sélection *a priori* de variables



```{r var_selection1, opts.label="fullwidth"}
par(mfrow=c(2,3))

plot(
  Net_demand ~ Load.1,
  data = rbind(train_data, val_data),
  pch = 1,
  cex = .5
)

plot(
  Net_demand ~ Load.7,
  data = rbind(train_data, val_data),
  pch = 1,
  cex = .5
)

# Plots on TEMP
plot(
  Net_demand ~ Temp,
  data = rbind(train_data, val_data),
  pch = 1,
  cex = .5
)

plot(
  Net_demand ~ Temp_s99,
  data = rbind(train_data, val_data),
  pch = 1,
  cex = .5
)

boxplot(Net_demand ~ WeekDays, data = rbind(train_data, val_data))
boxplot(Net_demand ~ WeekDays3, data = rbind(train_data, val_data))


```



```{r var_selection2, opts.label="fullwidth"}
par(mfrow=c(3, 2))

acf(Data0_clean$Net_demand)

plot(
  Net_demand ~ Load.1,
  data = rbind(train_data, val_data),
  pch = 1,
  cex = .5
)

nacf <- acf(Data0_clean$Net_demand, plot = FALSE)
nacf.df <- with(nacf, data.frame(lag, acf))

ggarrange(
 rbind(train_data, val_data) %>% 
    ggplot(aes(Load.1, Net_demand, colour = WeekDays3)) +
    geom_point() +
   theme_classic() +
  theme(legend.position = "bottom") +
  labs(x = "Load lag 1 (MW)", y = "Net demand (MW)", colour = "WeekDays3"),
ggAcf(Data0_clean$Net_demand, lag.max = 35) +
    labs(x = "Lag (day)", y = "ACF", title = "") +
    theme_classic()
)

```


# Modélisation

## Modèles linéaires

Pour vérifier l'importance des variables a priori sélectionnées, nous avons commencé par des modèles linéaires simples, multiples et quantiles.

### Importance du jour de la semaine et de la température

### Prendre en compte la saisonnalité

Notre première tentative pour prendre en compte la saisonnalité des données, à la fois mensuelle et hebdomadaire, a reposé sur une analyse de Fourier. 

## GAM

## Aggrégation d'experts

# Conclusion et discussion


